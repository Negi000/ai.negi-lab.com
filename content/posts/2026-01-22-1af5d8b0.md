---
title: "UC Berkeley発の高速推論エンジン「SGLang」がRadixArkとして商用化。4億ドルの評価額でAI推論市場に挑む"
date: 2026-01-22T00:00:00+09:00
description: "UC BerkeleyのIon Stoica教授の研究室から生まれた「SGLang」が、新会社RadixArkとしてスピンアウト。大手VCのAccelなど..."
cover:
  image: "/images/posts/2026-01-22-1af5d8b0.png"
  alt: "AI generated thumbnail"
  relative: false
categories:
  - "AI News"
tags:
  - "GenAI"
  - "速報"
  - "AIニュース"
---
## 3行要約

- UC BerkeleyのIon Stoica教授の研究室から生まれた「SGLang」が、新会社RadixArkとしてスピンアウト
- 大手VCのAccelなどから資金を調達し、評価額は約4億ドル（約600億円）に到達
- 開発者がLLMをより高速・低コストで動かすための「推論レイヤー」の競争が激化

## 何が発表されたのか

AI界隈で非常に注目されていたオープンソースプロジェクト「SGLang」が、正式に「RadixArk」という企業として独立することが明らかになりました。

SGLangは、もともとUC BerkeleyのIon Stoica教授（DatabricksやAnyscaleの共同創業者としても有名ですね）の研究室で開発されたプロジェクトです。これまで「LLMをいかに効率よく、高速に動かすか」という課題に対して、プログラミングインターフェースとランタイム（実行環境）の両面からアプローチしてきました。

今回のスピンアウトでは、著名なベンチャーキャピタルであるAccelなどから資金を調達しており、その評価額は4億ドルに達しているとのことです。これは、単なるオープンソースプロジェクトが、AIインフラの基幹を担う商用プラットフォームへと進化したことを意味しています。

## 競合との比較

RadixArk（SGLang）は、ChatGPTやClaudeのような「AIモデルそのもの」を提供するサービスではなく、それらのモデルを動かすための「エンジン」を提供する立ち位置です。

| 項目 | RadixArk (SGLang) | ChatGPT (OpenAI) | Claude (Anthropic) |
|------|-----------|---------|--------|
| 主な役割 | 推論エンジン・最適化フレームワーク | AIチャットサービス・モデル提供 | AIチャットサービス・モデル提供 |
| ターゲット | 開発者・AIインフラエンジニア | 一般ユーザー・企業利用者 | 一般ユーザー・企業利用者 |
| 主な強み | スループットの高さ、柔軟な制御 | 圧倒的な知名度と多機能性 | 高い論理的思考力と安全性 |
| 形態 | オープンソースベース / B2Bインフラ | クローズドなSaaS | クローズドなSaaS |

## 業界への影響

今回のRadixArkの台頭は、AI業界が「モデルの開発」から「推論の効率化」へと大きく舵を切っていることを象徴しています。

第一に、企業のコスト削減です。現在、多くの企業が独自のLLMを運用しようとしていますが、その推論コスト（GPUコスト）が大きな負担となっています。SGLangのような高速なエンジンが商用サポートされることで、企業はより安価に、かつ高速にAIサービスを提供できるようになります。

第二に、推論市場の標準化です。これまではNVIDIAの「TensorRT-LLM」や「vLLM」といったプロジェクトが先行していましたが、RadixArkが強力な資金力を持って参入することで、推論スタックのデファクトスタンダードを巡る争いがさらに激しくなるでしょう。

第三に、オープンソース・エコシステムの強化です。研究成果がこれほどの高評価でビジネス化される流れは、アカデミアの研究者にとっても大きな刺激となり、さらなる技術革新を加速させるはずです。

## 私の見解

正直なところ、このニュースを聞いて「ついに来たか」という感想を持ちました。SGLangは、開発者の間ではその圧倒的なスループットの高さですでに有名でしたが、これからは「商用版」として企業の基幹システムにも入り込んでいくことになりますね。

個人的には、かつてSIerでシステムのパフォーマンス改善に追われていた経験から、こういった「インフラの低層を最適化する技術」には並々ならぬ価値を感じます。AIが社会に浸透するためには、賢さだけでなく「安さと速さ」が絶対に必要だからです。

RadixArkが今後、vLLMなどの強力なライバルとどう差別化していくのか、そしてDatabricksなどとの連携がどう進むのか、非常に楽しみです。皆さんも、自分のサービスにLLMを組み込む際は、ぜひ一度SGLang（RadixArk）の動向をチェックしてみてください。

---

📚 **関連情報をもっと知りたい方へ**

<div style="display: flex; gap: 10px; flex-wrap: wrap; margin: 15px 0;">
<a href="https://www.amazon.co.jp/s?k=NVIDIA%20RTX%206000%20Ada&tag=negi3939-22" target="_blank" rel="noopener sponsored" style="padding: 8px 16px; background: #ff9900; color: white; text-decoration: none; border-radius: 6px; font-size: 14px;">📖 Amazonで関連書籍を探す</a>
<a href="https://hb.afl.rakuten.co.jp/hgc/5000cbfd.5f52567b.5000cbff.924460a4/?pc=https%3A%2F%2Fsearch.rakuten.co.jp%2Fsearch%2Fmall%2FNVIDIA%2520RTX%25206000%2520Ada%2F&m=https%3A%2F%2Fsearch.rakuten.co.jp%2Fsearch%2Fmall%2FNVIDIA%2520RTX%25206000%2520Ada%2F" target="_blank" rel="noopener sponsored" style="padding: 8px 16px; background: #bf0000; color: white; text-decoration: none; border-radius: 6px; font-size: 14px;">🛒 楽天で探す</a>
</div>
